{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48531b30-f512-42cc-a30a-8be3645be6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 02:04:45.355119: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 02:04:45.409273: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-11 02:04:45.409334: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-11 02:04:45.412674: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-11 02:04:45.430899: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 02:04:45.431866: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 02:04:49.009214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(\"images-ann-split/train\")\n",
    "    shutil.rmtree(\"images-ann-split/test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1318b8ca-d45e-4077-b83d-9d13fbfdbd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"images-ann-split/train/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"images-ann-split/train/no_damage\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Path(\"images-ann-split/test/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"images-ann-split/test/no_damage\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "561ff90e-4f92-443b-82e0-53cb24b7ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_damage_file_paths = os.listdir('images/damage')\n",
    "all_no_damage_file_paths = os.listdir('images/no_damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23bdcb2a-ed52-47db-a156-9aa85688787a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train damage image count:  11336\n",
      "test damage image count:  2834\n",
      "len of overlap:  0\n",
      "train no damage image count:  5721\n",
      "test no damage image count:  1431\n",
      "len of overlap:  0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_damage_paths = random.sample(all_damage_file_paths, int(len(all_damage_file_paths)*0.8))\n",
    "print(\"train damage image count: \", len(train_damage_paths))\n",
    "test_damage_paths = [ p for p in all_damage_file_paths if p not in train_damage_paths]\n",
    "print(\"test damage image count: \", len(test_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_damage_paths if p in test_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))\n",
    "\n",
    "train_no_damage_paths = random.sample(all_no_damage_file_paths, int(len(all_no_damage_file_paths)*0.8))\n",
    "print(\"train no damage image count: \", len(train_no_damage_paths))\n",
    "test_no_damage_paths = [ p for p in all_no_damage_file_paths if p not in train_no_damage_paths]\n",
    "print(\"test no damage image count: \", len(test_no_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_no_damage_paths if p in test_no_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e2b3ce-5479-4174-b510-a8ee0a7cfdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train/damage:  11336\n",
      "Files in train/no_damage:  5721\n",
      "Files in test/damage:  2834\n",
      "Files in test/no_damage:  1431\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "for p in train_damage_paths:\n",
    "    shutil.copyfile(os.path.join('images/damage', p), os.path.join('images-ann-split/train/damage', p) )\n",
    "    \n",
    "for p in test_damage_paths:\n",
    "    shutil.copyfile(os.path.join('images/damage', p), os.path.join('images-ann-split/test/damage', p) )\n",
    "\n",
    "for p in train_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('images/no_damage', p), os.path.join('images-ann-split/train/no_damage', p) )\n",
    "\n",
    "for p in test_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('images/no_damage', p), os.path.join('images-ann-split/test/no_damage', p) )\n",
    "\n",
    "\n",
    "# check counts:\n",
    "print(\"Files in train/damage: \", len(os.listdir(\"images-ann-split/train/damage\")))\n",
    "print(\"Files in train/no_damage: \", len(os.listdir(\"images-ann-split/train/no_damage\")))\n",
    "\n",
    "print(\"Files in test/damage: \", len(os.listdir(\"images-ann-split/test/damage\")))\n",
    "print(\"Files in test/no_damage: \", len(os.listdir(\"images-ann-split/test/no_damage\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56373681-b387-4926-8d3e-535658faab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.4-py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m147.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m152.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting etils[enp,epath,etree]>=0.9.0\n",
      "  Downloading etils-1.8.0-py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.1/156.1 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (1.26.3)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (4.23.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (5.9.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.31.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (2.4.0)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m272.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Collecting array-record>=0.5.0\n",
      "  Downloading array_record-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m321.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m315.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting importlib_resources\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.9.0)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2023.11.17)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m269.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m321.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.20\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m319.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21483 sha256=80f138d7adf5ba0dc27e8cf9af7302619f341ef279cc1ae7d405dfb518499247\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-2a5khmhk/wheels/74/05/89/d0909dd6ebad0a26f2b4dcb2499b1d65999c5b6ed416be7f85\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, tqdm, toml, protobuf, promise, importlib_resources, fsspec, etils, click, absl-py, googleapis-common-protos, tensorflow-metadata, array-record, tensorflow_datasets\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tfds is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 array-record-0.5.1 click-8.1.7 dm-tree-0.1.8 etils-1.8.0 fsspec-2024.3.1 googleapis-common-protos-1.63.0 importlib_resources-6.4.0 promise-2.3 protobuf-3.20.3 tensorflow-metadata-1.14.0 tensorflow_datasets-4.9.4 toml-0.10.2 tqdm-4.66.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_datasets --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78875e8f-cdbd-4ef1-b4dd-18f4fcacfd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17057 files belonging to 2 classes.\n",
      "Using 13646 files for training.\n",
      "Using 3411 files for validation.\n",
      "Found 4265 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = 'images-ann-split/train'\n",
    "test_data_dir = 'images-ann-split/test'\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "train_data_dir,\n",
    "validation_split=0.2,\n",
    "subset=\"both\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "test_data_dir,\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "440088f8-2e4c-43e3-86ab-a8ce731bb5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = Rescaling(scale=1.0/255)\n",
    "train_rescale_ds = train_ds.map(lambda image,label:(rescale(image),label))\n",
    "val_rescale_ds = val_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a43ed4eb-6be7-42d0-a8e7-27453f21e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rescale_ds = test_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee1c8ddc-92c4-449e-bb2a-8f71693870ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "image_size=128*128\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "# input layer\n",
    "model.add(Flatten(input_shape=(128,128,3)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Softmax activation function is selected for multiclass classification\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ca5db2-c15f-488b-83f2-a76b4d945c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f231853a-e730-4fb6-a298-d68ed87ceae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 49152)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6291584   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6291842 (24.00 MB)\n",
      "Trainable params: 6291842 (24.00 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ceffc7a-ea16-4436-b3b5-be7a8ba4e6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 13s 29ms/step - loss: 2.3083 - accuracy: 0.6290 - val_loss: 0.7310 - val_accuracy: 0.7027\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 12s 28ms/step - loss: 1.1024 - accuracy: 0.6593 - val_loss: 0.6799 - val_accuracy: 0.6910\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 12s 29ms/step - loss: 0.8005 - accuracy: 0.6806 - val_loss: 1.0507 - val_accuracy: 0.4670\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6787 - accuracy: 0.6916 - val_loss: 0.6195 - val_accuracy: 0.6719\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 12s 27ms/step - loss: 0.6402 - accuracy: 0.7024 - val_loss: 0.6864 - val_accuracy: 0.7068\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 12s 28ms/step - loss: 0.6026 - accuracy: 0.7122 - val_loss: 0.5481 - val_accuracy: 0.7429\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 12s 27ms/step - loss: 0.5410 - accuracy: 0.7423 - val_loss: 0.5280 - val_accuracy: 0.7672\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 12s 28ms/step - loss: 0.5520 - accuracy: 0.7370 - val_loss: 0.5305 - val_accuracy: 0.7722\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 12s 28ms/step - loss: 0.5550 - accuracy: 0.7363 - val_loss: 0.5357 - val_accuracy: 0.7555\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 11s 25ms/step - loss: 0.5391 - accuracy: 0.7451 - val_loss: 0.5292 - val_accuracy: 0.7643\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.5320 - accuracy: 0.7545 - val_loss: 0.5345 - val_accuracy: 0.7555\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 11s 25ms/step - loss: 0.5350 - accuracy: 0.7447 - val_loss: 0.5490 - val_accuracy: 0.7323\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 12s 27ms/step - loss: 0.5408 - accuracy: 0.7429 - val_loss: 0.5884 - val_accuracy: 0.6749\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 12s 28ms/step - loss: 0.5325 - accuracy: 0.7511 - val_loss: 0.5618 - val_accuracy: 0.7341\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.5370 - accuracy: 0.7477 - val_loss: 0.5316 - val_accuracy: 0.7575\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 12s 29ms/step - loss: 0.5307 - accuracy: 0.7477 - val_loss: 0.5237 - val_accuracy: 0.7619\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 13s 30ms/step - loss: 0.5180 - accuracy: 0.7620 - val_loss: 0.6137 - val_accuracy: 0.7145\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 13s 30ms/step - loss: 0.5300 - accuracy: 0.7535 - val_loss: 0.5236 - val_accuracy: 0.7719\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 13s 30ms/step - loss: 0.5203 - accuracy: 0.7610 - val_loss: 0.5092 - val_accuracy: 0.7781\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 12s 29ms/step - loss: 0.5078 - accuracy: 0.7740 - val_loss: 0.5031 - val_accuracy: 0.7795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f39b876d950>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_rescale_ds,batch_size=32,epochs=20,validation_data=val_rescale_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "807e3c68-cf00-40ff-a664-deb0c20f0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "## experimenting with varying layers and perceptrons\n",
    "## this model tests going from very large output shapes of each layer to our final output shape of 2\n",
    "model1 = Sequential()\n",
    "# input layer\n",
    "model1.add(Flatten(input_shape=(128,128,3)))\n",
    "\n",
    "model1.add(Dense(2048, activation='relu'))\n",
    "\n",
    "model1.add(Dense(1024, activation='relu'))\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "# Hidden layer\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Softmax activation function is selected for multiclass classification\n",
    "model1.add(Dense(2, activation='softmax'))\n",
    "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e430208b-79e5-48ea-98c0-6184c4e2e7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 49152)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              100665344 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103059074 (393.14 MB)\n",
      "Trainable params: 103059074 (393.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9072826-f963-4f06-a33e-6bee2a7e48df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 215s 500ms/step - loss: 1.2689 - accuracy: 0.6362 - val_loss: 0.5928 - val_accuracy: 0.7335\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 201s 470ms/step - loss: 0.6114 - accuracy: 0.6817 - val_loss: 0.6011 - val_accuracy: 0.6681\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 191s 446ms/step - loss: 0.6388 - accuracy: 0.6642 - val_loss: 0.6357 - val_accuracy: 0.6681\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 178s 417ms/step - loss: 0.6391 - accuracy: 0.6637 - val_loss: 0.6361 - val_accuracy: 0.6681\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 174s 408ms/step - loss: 0.6390 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 178s 418ms/step - loss: 0.6400 - accuracy: 0.6637 - val_loss: 0.6368 - val_accuracy: 0.6681\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 203s 474ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 198s 463ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 201s 470ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6360 - val_accuracy: 0.6681\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 195s 458ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 194s 454ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6357 - val_accuracy: 0.6681\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 199s 467ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 189s 442ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 185s 432ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6356 - val_accuracy: 0.6681\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 176s 413ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6357 - val_accuracy: 0.6681\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 183s 428ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 190s 444ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6361 - val_accuracy: 0.6681\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 203s 475ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6357 - val_accuracy: 0.6681\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 227s 531ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6356 - val_accuracy: 0.6681\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 189s 441ms/step - loss: 0.6390 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f39b8775e50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train_rescale_ds,batch_size=32,epochs=20,validation_data=val_rescale_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11907de6-7b73-438f-9313-468848c1c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "## experimenting with varying layers and perceptrons\n",
    "## this model tests going from smaller output shapes to large back to our final output shape of 2\n",
    "model2 = Sequential()\n",
    "# input layer\n",
    "model2.add(Flatten(input_shape=(128,128,3)))\n",
    "\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dense(1024, activation='relu'))\n",
    "# Hidden layer\n",
    "model2.add(Dense(2048, activation='relu'))\n",
    "\n",
    "# Softmax activation function is selected for multiclass classification\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4299fda-c176-4dfc-afb1-df7c5f561a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 12s 27ms/step - loss: 0.8030 - accuracy: 0.6601 - val_loss: 0.6355 - val_accuracy: 0.6681\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6394 - accuracy: 0.6637 - val_loss: 0.6355 - val_accuracy: 0.6681\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 12s 29ms/step - loss: 0.6394 - accuracy: 0.6637 - val_loss: 0.6355 - val_accuracy: 0.6681\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 12s 28ms/step - loss: 0.6393 - accuracy: 0.6637 - val_loss: 0.6357 - val_accuracy: 0.6681\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6392 - accuracy: 0.6637 - val_loss: 0.6355 - val_accuracy: 0.6681\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6392 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6392 - accuracy: 0.6637 - val_loss: 0.6356 - val_accuracy: 0.6681\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 12s 29ms/step - loss: 0.6392 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 11s 27ms/step - loss: 0.6392 - accuracy: 0.6637 - val_loss: 0.6356 - val_accuracy: 0.6681\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 11s 25ms/step - loss: 0.6393 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 11s 25ms/step - loss: 0.6392 - accuracy: 0.6637 - val_loss: 0.6356 - val_accuracy: 0.6681\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6392 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6391 - accuracy: 0.6637 - val_loss: 0.6356 - val_accuracy: 0.6681\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6392 - accuracy: 0.6637 - val_loss: 0.6356 - val_accuracy: 0.6681\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 12s 28ms/step - loss: 0.6391 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6392 - accuracy: 0.6637 - val_loss: 0.6356 - val_accuracy: 0.6681\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 11s 25ms/step - loss: 0.6390 - accuracy: 0.6637 - val_loss: 0.6357 - val_accuracy: 0.6681\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6394 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6391 - accuracy: 0.6637 - val_loss: 0.6357 - val_accuracy: 0.6681\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 11s 26ms/step - loss: 0.6391 - accuracy: 0.6637 - val_loss: 0.6364 - val_accuracy: 0.6681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f391aff8c90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_rescale_ds,batch_size=32,epochs=20,validation_data=val_rescale_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12f5d0d4-c085-4ed8-90e7-ea58b8ea501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 49152)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               6291584   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1024)              263168    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2048)              2099200   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8691074 (33.15 MB)\n",
      "Trainable params: 8691074 (33.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eaf5720-cc59-4b9f-9ce0-289aec76259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## experimenting with varying layers and perceptrons\n",
    "## this model tests going from smaller output shapes to large back to our final output shape of 2\n",
    "model3 = Sequential()\n",
    "# input layer\n",
    "model3.add(Flatten(input_shape=(128,128,3)))\n",
    "\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "# Hidden layer\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Softmax activation function is selected for multiclass classification\n",
    "model3.add(Dense(2, activation='softmax'))\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55a38e07-b542-4fd1-8810-52eba91a743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 9s 20ms/step - loss: 0.7209 - accuracy: 0.6457 - val_loss: 0.6501 - val_accuracy: 0.6722\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6149 - accuracy: 0.6776 - val_loss: 0.6355 - val_accuracy: 0.6681\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 8s 18ms/step - loss: 0.6390 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 8s 18ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6363 - val_accuracy: 0.6681\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6390 - accuracy: 0.6637 - val_loss: 0.6360 - val_accuracy: 0.6681\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6356 - val_accuracy: 0.6681\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6360 - val_accuracy: 0.6681\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6390 - accuracy: 0.6637 - val_loss: 0.6360 - val_accuracy: 0.6681\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6361 - val_accuracy: 0.6681\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 8s 20ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6357 - val_accuracy: 0.6681\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 8s 18ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6390 - accuracy: 0.6637 - val_loss: 0.6357 - val_accuracy: 0.6681\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6388 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 8s 18ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 8s 19ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 8s 18ms/step - loss: 0.6390 - accuracy: 0.6637 - val_loss: 0.6359 - val_accuracy: 0.6681\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 8s 18ms/step - loss: 0.6389 - accuracy: 0.6637 - val_loss: 0.6357 - val_accuracy: 0.6681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f391ac67510>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_rescale_ds,batch_size=32,epochs=20,validation_data=val_rescale_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddf6e69b-f126-4bc9-829b-67233fe43918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 49152)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               6291584   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6341378 (24.19 MB)\n",
      "Trainable params: 6341378 (24.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6712cd82-41c3-4238-b7b9-967f18b171df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_rescale_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44ffcee0-bac8-48e7-af1a-57c063e2fae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "y1_pred = model1.predict(test_rescale_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dca2981b-f253-485d-825f-57b79bba38a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y2_pred = model2.predict(test_rescale_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40261a0e-fa41-49cb-9baf-20ae05d1d4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y3_pred = model3.predict(test_rescale_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17ce54ea-2ae8-420a-91ec-80e1f5d3451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_rescale_ds, verbose = 0)\n",
    "test_loss1, test_accuracy1 = model1.evaluate(test_rescale_ds, verbose = 0)\n",
    "test_loss2, test_accuracy2 = model2.evaluate(test_rescale_ds, verbose = 0)\n",
    "test_loss3, test_accuracy3 = model3.evaluate(test_rescale_ds, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1cb3931-1b1e-4287-b7bb-4797b700a571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Model Accuracy and Loss\n",
      "=================================\n",
      " Model         Accuracy         Loss         Notes (max perceptrons do not include input perceptrons)\n",
      " 1             0.764            0.519        3 layers, max 128 perceptrons\n",
      " 2             0.664            0.638        6 layers, max 2048 perceptrons, larger to smaller\n",
      " 3             0.664            0.639        6 layers, max 2048 perceptrons, smaller to larger\n",
      " 4             0.664            0.638        6 layers, max 128 perceptrons\n"
     ]
    }
   ],
   "source": [
    "print(f\"Comparing Model Accuracy and Loss\")\n",
    "print(f\"=================================\")\n",
    "print(f\" Model         Accuracy         Loss         Notes (max perceptrons do not include input perceptrons)\")\n",
    "print(\" 1             \" + str(round(test_accuracy,3)) + \"            \" + str(round(test_loss,3)) + \"        3 layers, max 128 perceptrons\")\n",
    "print(\" 2             \" + str(round(test_accuracy1,3)) + \"            \" + str(round(test_loss1,3)) + \"        6 layers, max 2048 perceptrons, larger to smaller\")\n",
    "print(\" 3             \" + str(round(test_accuracy2,3)) + \"            \" + str(round(test_loss2,3)) + \"        6 layers, max 2048 perceptrons, smaller to larger\")\n",
    "print(\" 4             \" + str(round(test_accuracy3,3)) + \"            \" + str(round(test_loss3,3)) + \"        6 layers, max 128 perceptrons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75c6e217-7c74-466a-a6d7-00d48129c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ANN.keras\")\n",
    "model1.save(\"ANN1.keras\")\n",
    "model2.save(\"ANN2.keras\")\n",
    "model3.save(\"ANN3.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2037e9d-c666-405a-ab67-57dd7d1efc54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
